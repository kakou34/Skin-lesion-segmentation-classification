{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "IW8kHuL310mp",
        "bc6PYsmy4Yg_",
        "BG1DoytA4icy",
        "eI97c0oI4p3G",
        "-2hTDEEj9y7b",
        "sPQpQXcnEWPZ",
        "yOmSAOv2FqkB",
        "QWXs7FmwuJRU",
        "zuBBdQ7lLcCv",
        "OEzQac5jdBk_",
        "C6T4ADKu2Y7S",
        "hPOznBkR2dlV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to drive"
      ],
      "metadata": {
        "id": "umqvrWq5pNAK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojq16-zjpAVR",
        "outputId": "fc36035e-9e0c-4f48-e630-48bdfa52ac3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvf '/content/drive/MyDrive/CAD_Dataset/Challenge1/test.tgz' -C '/content/drive/MyDrive/CAD_Dataset/Challenge1/'"
      ],
      "metadata": {
        "id": "2pidUGHU45E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !tar -xvf '/content/drive/MyDrive/CAD_Dataset/Challenge2/test.tgz' -C '/content/drive/MyDrive/CAD_Dataset/Challenge2/'"
      ],
      "metadata": {
        "id": "tjL6qI186gKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import packages"
      ],
      "metadata": {
        "id": "wEfTXfqfpeTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mahotas\n",
        "!pip install mlxtend\n",
        "!pip install xgboost\n",
        "!pip install plantcv\n",
        "!pip install scikit-image --upgrade"
      ],
      "metadata": {
        "id": "dGUznlQvph1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################     GENERAL     ###########################################\n",
        "import math\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy.ma as ma\n",
        "from tabulate import tabulate\n",
        "import os\n",
        "import mahotas  \n",
        "import pickle\n",
        "\n",
        "################################## Computer Vision ###########################################\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "#from google.colab.patches import cv2_imshow  \n",
        "from scipy import ndimage\n",
        "from scipy.spatial.distance import dice\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from skimage import data, morphology\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from skimage.filters import threshold_multiotsu, threshold_otsu\n",
        "from skimage.morphology import skeletonize\n",
        "from plantcv import plantcv as pcv\n",
        "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
        "\n",
        "\n",
        "################################## MACHINE LEARNING  ###########################################\n",
        "import sklearn as sk\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, cohen_kappa_score, balanced_accuracy_score \n",
        "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, cross_val_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer, FunctionTransformer\n",
        "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
        "\n",
        "#models \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import RidgeCV\n",
        "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier, VotingClassifier\n",
        "from sklearn import linear_model\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "pMHCHyy4qmzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "WjKOroFGpilE"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW8kHuL310mp"
      },
      "source": [
        "### Preprocessing helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "croX56Z-3JKD"
      },
      "source": [
        "#### 0. Reading image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_img(img_id: str, challenge: str):\n",
        "  '''\n",
        "    read a preprocessed image from the dataset folders\n",
        "    Args:\n",
        "    - img_id (string): image folder name (without extension)\n",
        "    - challenge: Challenge1 (binary) or Challenge2 (multiclass)\n",
        "    Return:\n",
        "    - The RGB preprocessed image stored in a numpy ndarray.\n",
        "  '''\n",
        "  path = f\"/content/drive/MyDrive/CAD_Dataset/{challenge}/testX/{img_id}.jpg\"\n",
        "  print(path)\n",
        "  img = cv.imread(path)\n",
        "  img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  return img_rgb"
      ],
      "metadata": {
        "id": "RIXVYyEgfmQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBHHT_6UN_y3"
      },
      "outputs": [],
      "source": [
        "def read_img_prepro(img_id: str, challenge: str):\n",
        "  '''\n",
        "    read a preprocessed image from the dataset folders\n",
        "    Args:\n",
        "    - img_id (string): image folder name (without extension)\n",
        "    - challenge: Challenge1 (binary) or Challenge2 (multiclass)\n",
        "    Return:\n",
        "    - The RGB preprocessed image stored in a numpy ndarray.\n",
        "  '''\n",
        "  path = f\"/content/drive/MyDrive/CAD_Dataset/{challenge}/test_preprocessed/{img_id}.jpg\"\n",
        "  img = cv.imread(path)\n",
        "  img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
        "  return img_rgb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqLZwtav3Th0"
      },
      "outputs": [],
      "source": [
        "#### Function Test #### \n",
        "img_id = \"xxx00033\"\n",
        "img = read_img(img_id, 'Challenge1')\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0w3mQFg4P1C"
      },
      "source": [
        "#### 1. Vignette removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR7DuVz61feb"
      },
      "outputs": [],
      "source": [
        "def crop_img(img: np.ndarray, threshold: int=0):\n",
        "    '''\n",
        "    Crop the image to get the region of interest. Remove the vignette frame.\n",
        "    Analyze the value of the pixels in the diagonal of the image, from 0,0 to h,w and\n",
        "    take the points where this value crosses the threshold by the first time and for last.\n",
        "    Args:\n",
        "    - img (numpy ndarray): Image to crop.\n",
        "    - threshold (int): Value to split the diagonal into image and frame.\n",
        "    Return:\n",
        "    - The coordinates of the rectangle and the cropped image.\n",
        "    '''\n",
        "    # Get the image dimensions\n",
        "    h, w = img.shape[:2]\n",
        "    cd = math.gcd(h, w)  # Greatest Common Divider\n",
        "\n",
        "    # Get the coordinates of the pixels in the diagonal\n",
        "    y_coords = ([i for i in range(0, h, int(h/cd))], [i for i in range(h - int(h/cd), 0, -int(h/cd))])\n",
        "    x_coords = ([i for i in range(0, w, int(w/cd))], [i for i in range(0, w, int(w/cd))])\n",
        "\n",
        "    # Get the mean value of the pixels in the diagonal, form 0,0 to h,w \n",
        "    # and from h,0 to 0,w\n",
        "    coordinates = {'y1_1': 0, 'x1_1': 0, 'y2_1': h, 'x2_1': w, 'y1_2': h, 'x1_2': 0, 'y2_2': 0, 'x2_2': w}\n",
        "    for i in range(2):\n",
        "        d = []\n",
        "        y1_aux, x1_aux = 0, 0\n",
        "        y2_aux, x2_aux = h, w \n",
        "        for y, x in zip(y_coords[i], x_coords[i]):\n",
        "            d.append(np.mean(img[y, x, :]))\n",
        "\n",
        "        # Get the location of the first point where the threshold is crossed\n",
        "        for idx, value in enumerate(d):\n",
        "            if (value >= threshold and idx != 0):  # If there's no vignette, in idx=0 the value would be > thresh..\n",
        "                coordinates['y1_' + str(i + 1)] = y_coords[i][idx]\n",
        "                coordinates['x1_' + str(i + 1)] = x_coords[i][idx]\n",
        "                break\n",
        "\n",
        "        # Get the location of the last point where the threshold is crossed\n",
        "        for idx, value in enumerate(reversed(d)):\n",
        "            if (value >= threshold and idx != 0):  # If there's no vignette, in idx=0 the value would be > thresh..\n",
        "                coordinates['y2_' + str(i + 1)] = y_coords[i][len(y_coords[i])-idx]\n",
        "                coordinates['x2_' + str(i + 1)] = x_coords[i][len(x_coords[i])-idx]\n",
        "                break\n",
        "\n",
        "    # Set the coordinates to crop the image\n",
        "    y1 = max(coordinates['y1_1'], coordinates['y2_2'])\n",
        "    y2 = min(coordinates['y2_1'], coordinates['y1_2'])\n",
        "    x1 = max(coordinates['x1_1'], coordinates['x1_2'])\n",
        "    x2 = min(coordinates['x2_1'], coordinates['x2_2'])\n",
        "\n",
        "    img_new = img[y1:y2, x1:x2, :]\n",
        "\n",
        "    if img_new.shape[0] == 0 or img_new.shape[1] == 0:\n",
        "      img_new = img \n",
        "    \n",
        "    return img_new #y1, y2, x1, x2, img[y1:y2, x1:x2, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaYfX0V67GKI"
      },
      "outputs": [],
      "source": [
        "#### Function Test #### \n",
        "img_crop= crop_img(img)\n",
        "\n",
        "plt.imshow(img_crop)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc6PYsmy4Yg_"
      },
      "source": [
        "#### 2. Hair Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYGF8NPv4fIx"
      },
      "outputs": [],
      "source": [
        "def inpaint(src: np.ndarray, se_size: int = 15):    \n",
        "    '''param : src --> Color image\n",
        "               se_size --> Size of the structuring elements\n",
        "      return : Inp --> Inpainted image with hair removed '''\n",
        "\n",
        "    # Convert the original image to grayscale if it has > 1 channel\n",
        "    if (len(src.shape)==3):\n",
        "      channel = cv.cvtColor(src, cv.COLOR_BGR2GRAY)\n",
        "    else:\n",
        "      channel = src\n",
        "\n",
        "    # Structuring Element for the morphological filtering\n",
        "    \n",
        "    se = cv.getStructuringElement(1, (se_size, se_size))  # (17x17) '+' shaped SE\n",
        "    se2 = np.array(list(reversed(list(zip(*np.eye(se_size)))))) + np.eye(se_size)\n",
        "    se2[int(se_size/2), int(se_size/2)] = 1  # (17x17) 'X' shaped SE\n",
        "    \n",
        "    # Perform the blackHat filtering on the grayscale image to find the \n",
        "    # hair (and other objects') countours\n",
        "    blackhat = cv.morphologyEx(channel, cv.MORPH_BLACKHAT, se)\n",
        "    blackhat2 = cv.morphologyEx(channel, cv.MORPH_BLACKHAT, se2.astype(np.uint8))\n",
        "    bHat = blackhat + blackhat2\n",
        "\n",
        "    # Intensify the countours detected in preparation for the inpainting algorithm\n",
        "    ret, thresh = cv.threshold(bHat, 10, 255, cv.THRESH_BINARY)\n",
        "\n",
        "    # Inpaint the original image depending on the mask\n",
        "    Inp = cv.inpaint(src, thresh, 1, cv.INPAINT_TELEA)\n",
        "\n",
        "    return Inp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfTPFBrZ9JtV"
      },
      "outputs": [],
      "source": [
        "#### Function Test 1 #### \n",
        "img_inp = inpaint(img)\n",
        "plt.imshow(img_inp)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BG1DoytA4icy"
      },
      "source": [
        "#### 3. Color Constancy "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AaeWvpa4lqb"
      },
      "outputs": [],
      "source": [
        "def shade_of_gray_cc(img: np.ndarray, power:int =6, gamma=None):\n",
        "    \"\"\"\n",
        "    img (numpy array): the original image with format of (h, w, c)\n",
        "    power (int): the degree of norm, 6 is used in reference paper\n",
        "    gamma (float): the value of gamma correction, 2.2 is used in reference paper\n",
        "    \"\"\"\n",
        "    img_dtype = img.dtype\n",
        "\n",
        "    if gamma is not None:\n",
        "        img = img.astype('uint8')\n",
        "        look_up_table = np.ones((256,1), dtype='uint8') * 0\n",
        "        for i in range(256):\n",
        "            look_up_table[i][0] = 255 * pow(i/255, 1/gamma)\n",
        "        img = cv.LUT(img, look_up_table)\n",
        "\n",
        "    img = img.astype('float32')\n",
        "    img_power = np.power(img, power)\n",
        "    rgb_vec = np.power(np.mean(img_power, (0,1)), 1/power)\n",
        "    rgb_norm = np.sqrt(np.sum(np.power(rgb_vec, 2.0)))\n",
        "    rgb_vec = rgb_vec/rgb_norm\n",
        "    rgb_vec = 1/(rgb_vec*np.sqrt(3))\n",
        "    img = np.multiply(img, rgb_vec)\n",
        "\n",
        "    # Andrew Anikin suggestion\n",
        "    img = np.clip(img, a_min=0, a_max=255)\n",
        "    \n",
        "    return img.astype(img_dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5RksYVU-CrN"
      },
      "outputs": [],
      "source": [
        "#### Function Test #### \n",
        "img_cc = shade_of_gray_cc(img)\n",
        "plt.imshow(img_cc)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI97c0oI4p3G"
      },
      "source": [
        "#### 4. Other"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvJWofK_ChWS"
      },
      "outputs": [],
      "source": [
        "def resize_im(img: np.ndarray, max_size: int):  \n",
        "  '''\n",
        "    function to resize an image while maintaining the aspect ratio\n",
        "    args: \n",
        "      - img: (np.ndarray) image to be resized \n",
        "      - max_size: the new size of the largest side of the image\n",
        "  ''' \n",
        "  scale_percent = round((max_size / max(img.shape[0], img.shape[1])),2) \n",
        "  width = int(img.shape[1] * scale_percent)\n",
        "  height = int(img.shape[0] * scale_percent)\n",
        "  dim = (width, height)\n",
        "  # Resize image\n",
        "  image = cv.resize(img, dim, interpolation = cv.INTER_CUBIC)\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rh6a7zD9t3n"
      },
      "outputs": [],
      "source": [
        "###### Test function #############\n",
        "resized = resize_im(img, 500);\n",
        "print(f\"Before: {img.shape}\\nAfter: {resized.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIq-eEmax3ZR"
      },
      "source": [
        "Preprocessing function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWZVeAnZx2nO"
      },
      "outputs": [],
      "source": [
        "def preprocess(img: np.ndarray, max_size: int, crop_params=None, cc_params=None, remove_hair_params=None):\n",
        "      '''\n",
        "        function that runs the whole preprocessing pipeline over an image \n",
        "        args:\n",
        "          - img: (np.ndarray) image to be processed \n",
        "          - img_size: (int) new image sizes\n",
        "          - crop_params: (dict) parameters of cropping function stored in a dict\n",
        "          - cc_params: (dict) parameters of color normalization function stored in a dict\n",
        "          - remove_hair_params: (dict) parameters of hair removal function stored in a dict\n",
        "    returns: the preprocessed image stored in an ndarray\n",
        "      '''\n",
        "      if crop_params is not None:\n",
        "        img = crop_img(img, threshold=crop_params[\"threshold\"])\n",
        "\n",
        "      img = resize_im(img, max_size)\n",
        "\n",
        "      if cc_params is not None: \n",
        "        img = shade_of_gray_cc(img, power=cc_params[\"power\"], gamma=cc_params[\"gamma\"])\n",
        "\n",
        "      if remove_hair_params is not None: \n",
        "        img = inpaint(img, se_size =  remove_hair_params['se_size'])\n",
        "\n",
        "      return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRYy0tTC-a7S"
      },
      "outputs": [],
      "source": [
        "#### Function Test #### \n",
        "img_pp = preprocess(img, 500, crop_params= None, cc_params={\"gamma\": None, \"power\":6}, remove_hair_params={'se_size': 9})\n",
        "plt.imshow(img_pp)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2hTDEEj9y7b"
      },
      "source": [
        "### Feature Extraction helper functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPQpQXcnEWPZ"
      },
      "source": [
        "#### Global"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhdFfSCc-jpa"
      },
      "outputs": [],
      "source": [
        "def variegation(Im: np.ndarray):\n",
        "  '''param : Im            --> RGB image\n",
        "    return : C_r, C_g, C_b --> Color Variegation measures for each RGB Channel '''  \n",
        "\n",
        "  # Split Color channels  \n",
        "  lesion_r = Im[:, :, 0]\n",
        "  lesion_g = Im[:, :, 1]\n",
        "  lesion_b = Im[:, :, 2]\n",
        "\n",
        "  # Compute the normalized Standard Deviation of each channel\n",
        "  C_r = np.std(lesion_r) / np.max(lesion_r)\n",
        "  C_g = np.std(lesion_g) / np.max(lesion_g)\n",
        "  C_b = np.std(lesion_b) / np.max(lesion_b)\n",
        "\n",
        "  variegation = np.array([C_r, C_g, C_b]).reshape(1, -1)\n",
        "  return variegation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rRQ5GDl-jrt",
        "outputId": "2d1f586e-2680-4f14-aca5-8cace32f7b43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variegation: [[0.1049008  0.11762126 0.13037078]]\n"
          ]
        }
      ],
      "source": [
        "### Test function ### \n",
        "vari = variegation(img)\n",
        "\n",
        "print(f\"Variegation: {vari}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOmSAOv2FqkB"
      },
      "source": [
        "#### Color"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvOhHpCmFsd5"
      },
      "outputs": [],
      "source": [
        "def color_moments(Img: np.ndarray):\n",
        "    \"\"\" Extract Color Moments of an image.\n",
        "    --> param Img : ndarray, RGB image\n",
        "    --> return color_moments : ndarray, contains the 4 Central Color Moments \"\"\"\n",
        "\n",
        "    c1, c2, c3 = cv.split(Img)\n",
        "    color_feature = []  # Initialize the color feature\n",
        "\n",
        "    # -- The first central moment - average\n",
        "    c1_mean = np.mean(c1)  # np.sum(h)/float(N)\n",
        "    c2_mean = np.mean(c2)  # np.sum(s)/float(N)\n",
        "    c3_mean = np.mean(c3)  # np.sum(v)/float(N)\n",
        "    color_feature.extend([c1_mean, c2_mean, c3_mean])\n",
        "    # -- The second central moment - standard deviation\n",
        "    c1_std = np.std(c1)  # np.sqrt(np.mean(abs(h - h.mean())**2))\n",
        "    c2_std = np.std(c2)  # np.sqrt(np.mean(abs(s - s.mean())**2))\n",
        "    c3_std = np.std(c3)  # np.sqrt(np.mean(abs(v - v.mean())**2))\n",
        "    color_feature.extend([c1_std, c2_std, c3_std])\n",
        "    # -- The third central moment - the third root of the skewness\n",
        "    c1_skewness = np.mean(abs(c1 - c1.mean())**3)\n",
        "    c2_skewness = np.mean(abs(c2 - c2.mean())**3)\n",
        "    c3_skewness = np.mean(abs(c3 - c3.mean())**3)\n",
        "    c1_thirdMoment = c1_skewness**(1./3)\n",
        "    c2_thirdMoment = c2_skewness**(1./3)\n",
        "    c3_thirdMoment = c3_skewness**(1./3)\n",
        "    color_feature.extend([c1_thirdMoment, c2_thirdMoment, c3_thirdMoment])\n",
        "    # -- The fourth central moment - the variance\n",
        "    c1_var = c1_std**2  # (np.mean(abs(h - h.mean())**2))\n",
        "    c2_var = c2_std**2  # (np.mean(abs(s - s.mean())**2))\n",
        "    c3_var = c3_std**2  # (np.mean(abs(v - v.mean())**2))\n",
        "    color_feature.extend([c1_var, c2_var, c3_var])\n",
        "\n",
        "    return np.array(color_feature).reshape(1, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4egQ86y0Hc9x"
      },
      "outputs": [],
      "source": [
        "### Test function ### \n",
        "col_mom = color_moments(img)\n",
        "print(col_mom)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4C3b84QL3Mr"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "def extract_color_histogram(Img: np.ndarray, n_bins: int=256):\n",
        "    \"\"\"Extract Color histogram of an image.\n",
        "    --> param Img : ndarray, RGB image\n",
        "    --> return feature : ndarray, contains n_bins*n_bins*n_bins of RGB, HSV & L.a.b histogram features of the image\n",
        "    \"\"\"\n",
        "    # --- RGB : ---\n",
        "    rgb_ft = []\n",
        "    channels = cv.split(Img)\n",
        "    colors = (\"r\", \"g\", \"b\")\n",
        "    for (channel, color) in zip(channels, colors):  \n",
        "      hist = cv.calcHist([channel], [0], None, [n_bins], [1, 256])     # For each image channel, the normalized histogram is computed\n",
        "      hist = hist/hist.sum()\n",
        "      #cv.normalize(hist, hist, norm_type=cv.NORM_MINMAX)\n",
        "      rgb_ft.extend(hist)  \n",
        "    rgb_ft = np.array(rgb_ft).reshape(1, -1)\n",
        "\n",
        "    # --- HSV : ---\n",
        "    hsv_ft = []\n",
        "    hsv = cv.cvtColor(Img, cv.COLOR_RGB2HSV) # Convert the image to HSV color-space\n",
        "    channels = cv.split(hsv)\n",
        "    colors = (\"h\", \"s\", \"v\")\n",
        "    for (channel, color) in zip(channels, colors):\n",
        "      hist = cv.calcHist([channel], [0], None, [n_bins], [1, 256])  # For each image channel, the normalized histogram is computed\n",
        "      hist = hist/hist.sum()\n",
        "      #cv.normalize(hist, hist, norm_type=cv.NORM_MINMAX)\n",
        "      hsv_ft.extend(hist)  \n",
        "    hsv_ft = np.array(hsv_ft).reshape(1, -1)\n",
        "\n",
        "    # --- LAB : ---\n",
        "    lab_ft = []\n",
        "    lab = cv.cvtColor(Img, cv.COLOR_RGB2LAB) # Convert the image to Lab color-space\n",
        "    channels = cv.split(lab)\n",
        "    colors = (\"l\", \"a\", \"b\")\n",
        "    for (channel, color) in zip(channels, colors):\n",
        "      hist = cv.calcHist([channel], [0], None, [n_bins], [1, 256])  # For each image channel, the normalized histogram is computed\n",
        "      hist = hist/hist.sum()\n",
        "      #cv.normalize(hist, hist, norm_type=cv.NORM_MINMAX)\n",
        "      lab_ft.extend(hist)  \n",
        "    lab_ft = np.array(lab_ft).reshape(1, -1)\n",
        "\n",
        "    return rgb_ft, hsv_ft, lab_ft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfHcrcOgMshc"
      },
      "outputs": [],
      "source": [
        "### Test function ### \n",
        "rgb, hsv, lab = extract_color_histogram(img, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-Aangg2F_cc"
      },
      "outputs": [],
      "source": [
        "print(hsv.shape)\n",
        "print(rgb.shape)\n",
        "print(lab.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWXs7FmwuJRU"
      },
      "source": [
        "#### Texture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_9sOF7euIKQ"
      },
      "outputs": [],
      "source": [
        "def extract_texture_fd(Img: np.ndarray, P:int =16, R:int =2):\n",
        "    \"\"\"Extract Texture Features\n",
        "    --> param Img : ndarray, RGB image\n",
        "              P, R: integers, LBP parameters\n",
        "    --> return texture_features : ndarrays, contains Texture descriptors of the image\n",
        "    \"\"\"\n",
        "    blue_Img = Img[:,:,2]  # Use the blue channel of the Image\n",
        "\n",
        "    # Local Binary Pattern (LBP) : \n",
        "    lbp = local_binary_pattern(blue_Img, P, R, method='uniform')  # P24 R8\n",
        "    n_bins = int(lbp.max() + 1)\n",
        "    lbp_fd, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
        "\n",
        "    # Haralick : \n",
        "    haralick_fd = mahotas.features.haralick(blue_Img).mean(axis=0)  # 14 Statistics\n",
        "\n",
        "    # Gray Level Co-occurance Matrix (GLCM) : \n",
        "    distance = [1]\n",
        "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
        "    properties = ['correlation', 'homogeneity', 'contrast', 'energy', 'dissimilarity']\n",
        "    glcm_fd = []\n",
        "    glcm_mat = graycomatrix(blue_Img, distances=distance, angles=angles, symmetric=True, normed=True)\n",
        "    glcm_fd = np.hstack([graycoprops(glcm_mat, props).ravel() for props in properties])\n",
        "    lbp_fd = np.array(lbp_fd).reshape(1, -1)\n",
        "    haralick_fd = np.array(haralick_fd).reshape(1, -1)\n",
        "    glcm_fd = np.array(glcm_fd).reshape(1, -1)\n",
        "\n",
        "    return lbp_fd, haralick_fd, glcm_fd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-4WXEgXuIyX"
      },
      "outputs": [],
      "source": [
        "lbp_f, haralick_f, glcm_f = extract_texture_fd(img, 16, 2)\n",
        "print(lbp_f.shape)\n",
        "print(haralick_f.shape)\n",
        "print(glcm_f.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuBBdQ7lLcCv"
      },
      "source": [
        "#### All"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PumtEL9ICuir"
      },
      "outputs": [],
      "source": [
        "def extract_save_features(df, challenge, lbp_params = None):\n",
        "  '''\n",
        "    function that extracts all features from all images\n",
        "    args: \n",
        "      - df: (pandas dataframe): dataframe with image ids\n",
        "      - challenge: (string) challeng1 or challeng2\n",
        "      - lbp_params: (dict) parameters for LBP function\n",
        "    returns all feature vectors of all images stacked vertically in a numpy array\n",
        "  '''\n",
        "\n",
        "    # Initialize empty arrays to store the features \n",
        "  variegation_fd = []\n",
        "  color_feature_fd = []\n",
        "  rgb_ft_fd = []\n",
        "  hsv_ft_fd = []\n",
        "  lab_ft_fd = []\n",
        "\n",
        "  # Texture features : \n",
        "  lbp_fd = []\n",
        "  haralick_fd = []\n",
        "  glcm_fd = []    \n",
        "\n",
        "  for i, row in df.iterrows():\n",
        "      print(i)\n",
        "      img_id = row['image_id']\n",
        "      img = read_img_prepro(img_id, challenge)\n",
        "\n",
        "      varieg = variegation(img)\n",
        "      variegation_fd.append(varieg)\n",
        "\n",
        "      col_mom = color_moments(img)\n",
        "      color_feature_fd.append(col_mom)\n",
        "\n",
        "      rgb_tr, hsv_tr, lab_tr = extract_color_histogram(img, 64)\n",
        "      rgb_ft_fd.append(rgb_tr)\n",
        "      hsv_ft_fd.append(hsv_tr)\n",
        "      lab_ft_fd.append(lab_tr)\n",
        "\n",
        "      lbp_f, haralick_f, glcm_f = extract_texture_fd(img, P=lbp_params['P'], R=lbp_params['R'])\n",
        "      lbp_fd.append(lbp_f)\n",
        "      haralick_fd.append(haralick_f)\n",
        "      glcm_fd.append(glcm_f)\n",
        "\n",
        "  variegation_fd =  np.squeeze(np.array(variegation_fd), axis=1)\n",
        "  color_feature_fd =  np.squeeze(np.array(color_feature_fd), axis=1)\n",
        "  rgb_ft_fd = np.squeeze(np.array(rgb_ft_fd), axis=1)\n",
        "  hsv_ft_fd =  np.squeeze(np.array(hsv_ft_fd), axis=1)\n",
        "  lab_ft_fd =  np.squeeze(np.array(lab_ft_fd), axis=1)\n",
        "  lbp_fd =  np.squeeze(np.array(lbp_fd), axis=1)\n",
        "  haralick_fd =  np.squeeze(np.array(haralick_fd), axis=1)\n",
        "  glcm_fd =  np.squeeze(np.array(glcm_fd), axis=1)\n",
        "    \n",
        "  return variegation_fd, color_feature_fd, rgb_ft_fd, hsv_ft_fd, lab_ft_fd, lbp_fd, haralick_fd, glcm_fd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save preprocessed images"
      ],
      "metadata": {
        "id": "OEzQac5jdBk_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wYfTYn2N_y_"
      },
      "outputs": [],
      "source": [
        "def save_imgs(df, challenge, img_size, crop_params=None, cc_params=None, remove_hair_params=None):\n",
        "  '''\n",
        "    function that preprocesses images and saves them to a directory \n",
        "    args: \n",
        "      - df: (dataframe): dataframe with images ids\n",
        "      - challenge: (string) Challenge1 or Challenge2\n",
        "      - img_size: (int) new image sizes\n",
        "      - crop_params: (dict) parameters of cropping function stored in a dict\n",
        "      - cc_params: (dict) parameters of color normalization function stored in a dict\n",
        "      - remove_hair_params: (dict) parameters of hair removal function stored in a dict\n",
        "    returns: nothing\n",
        "  '''\n",
        "  for i, row in df.iterrows():\n",
        "    img_id = row['image_id']\n",
        "    print(img_id)\n",
        "    img = read_img(img_id, challenge)\n",
        "    img = preprocess(img, img_size, crop_params, cc_params, remove_hair_params)\n",
        "    img_pil = Image.fromarray(img)\n",
        "    img_pil.save(f'/content/drive/MyDrive/CAD_Dataset/{challenge}/test/preprocessed/{img_id}.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating CSV files with file names for each challenge\n",
        "img_ids_1 = []\n",
        "img_ids_2 = []\n",
        "\n",
        "# Challenge 1\n",
        "directory = \"/content/drive/MyDrive/CAD_Dataset/Challenge1/testX\" \n",
        "for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        img_id = f[-12:-4]\n",
        "        # print(img_id)\n",
        "        img_ids_1.append(img_id)\n",
        "\n",
        "# Challenge 2\n",
        "directory = \"/content/drive/MyDrive/CAD_Dataset/Challenge2/testX\" \n",
        "for filename in os.listdir(directory):\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    if os.path.isfile(f):\n",
        "        img_id = f[-12:-4]\n",
        "        # print(img_id)\n",
        "        img_ids_2.append(img_id)\n",
        "        \n",
        "img_ids_1 = sorted(img_ids_1)\n",
        "img_ids_2 = sorted(img_ids_2)\n",
        "test1_df = pd.DataFrame(list(zip(img_ids_1)), columns =['image_id'])\n",
        "test2_df = pd.DataFrame(list(zip(img_ids_2)), columns =['image_id'])\n",
        "\n",
        "test1_df.to_csv('/content/drive/MyDrive/CAD_Dataset/Challenge1/test.csv')\n",
        "test2_df.to_csv('/content/drive/MyDrive/CAD_Dataset/Challenge2/test.csv')"
      ],
      "metadata": {
        "id": "HTGeXb_siNDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df_challenge1 = pd.read_csv(\"/content/drive/MyDrive/CAD_Dataset/Challenge1/test.csv\")\n",
        "print(len(test_df_challenge1))\n",
        "test_df_challenge2 = pd.read_csv(\"/content/drive/MyDrive/CAD_Dataset/Challenge2/test.csv\")\n",
        "print(len(test_df_challenge2))"
      ],
      "metadata": {
        "id": "1Kt2c2EldPp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr0h4uIPN_y_"
      },
      "outputs": [],
      "source": [
        "save_imgs(test_df_challenge1, 'train', 500, crop_params={'threshold':50}, cc_params={'power':6, 'gamma':None}, remove_hair_params={'se_size': 9})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARsiXA5s_5JM"
      },
      "outputs": [],
      "source": [
        "save_imgs(test_df_challenge2, 'val', 500, crop_params={'threshold':50}, cc_params={'power':6, 'gamma':None}, remove_hair_params={'se_size': 9})"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Features "
      ],
      "metadata": {
        "id": "4p5UAYsopxWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge 1\n"
      ],
      "metadata": {
        "id": "C6T4ADKu2Y7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variegation_fd1, color_feature_fd1, rgb_fd1, hsv_fd1, lab_fd1, lbp_fd1, haralick_fd1, glcm_fd1 = extract_save_features(test_df_challenge1, \n",
        "                                                                                                                'Challenge1', \n",
        "                                                                                                                lbp_params={'P':16, 'R':2})"
      ],
      "metadata": {
        "id": "lTJdwBNVp1Sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----  Save the extracted features in our Save_Folder :  ----\n",
        "save_path = '/content/drive/MyDrive/CAD_Dataset/Challenge1/'\n",
        "\n",
        "# --  Save Train Features :\n",
        "if save_path is not None:      \n",
        "  os.makedirs(os.path.join(save_path, 'features_test'), exist_ok=True)\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_variegation_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(variegation_fd1, f)\n",
        "  print(\"test_variegation_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_color_feature_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(color_feature_fd1, f)\n",
        "  print(\"test_color_feature_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_rgb_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(rgb_fd1, f)\n",
        "  print(\"test_rgb_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_hsv_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(hsv_fd1, f)\n",
        "  print(\"test_hsv_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_lab_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(lab_fd1, f)\n",
        "  print(\"test_lab_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_lbp_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(lbp_fd1, f)\n",
        "  print(\"test_lbp_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_haralick_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(haralick_fd1, f)\n",
        "  print(\"test_haralick_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_glcm_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(glcm_fd1, f)\n",
        "  print(\"test_glcm_fd were saved..\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieXlsTpZzQAv",
        "outputId": "52110138-5a41-4745-c400-b666e8b90fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_variegation_fd were saved..\n",
            "\n",
            "test_color_feature_fd were saved..\n",
            "\n",
            "test_rgb_fd were saved..\n",
            "\n",
            "test_hsv_fd were saved..\n",
            "\n",
            "test_lab_fd were saved..\n",
            "\n",
            "test_lbp_fd were saved..\n",
            "\n",
            "test_haralick_fd were saved..\n",
            "\n",
            "test_glcm_fd were saved..\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge 2\n"
      ],
      "metadata": {
        "id": "hPOznBkR2dlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variegation_fd2, color_feature_fd2, rgb_fd2, hsv_fd2, lab_fd2, lbp_fd2, haralick_fd2, glcm_fd2 = extract_save_features(test_df_challenge2, \n",
        "                                                                                                                'Challenge2', \n",
        "                                                                                                                lbp_params={'P':16, 'R':2})"
      ],
      "metadata": {
        "id": "RLSpL6kuWdDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----  Save the extracted features in our Save_Folder :  ----\n",
        "save_path = '/content/drive/MyDrive/CAD_Dataset/Challenge2/'\n",
        "\n",
        "# --  Save Train Features :\n",
        "if save_path is not None:      \n",
        "  os.makedirs(os.path.join(save_path, 'features_test'), exist_ok=True)\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_variegation_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(variegation_fd2, f)\n",
        "  print(\"test_variegation_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_color_feature_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(color_feature_fd2, f)\n",
        "  print(\"test_color_feature_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_rgb_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(rgb_fd2, f)\n",
        "  print(\"test_rgb_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_hsv_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(hsv_fd2, f)\n",
        "  print(\"test_hsv_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_lab_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(lab_fd2, f)\n",
        "  print(\"test_lab_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_lbp_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(lbp_fd2, f)\n",
        "  print(\"test_lbp_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_haralick_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(haralick_fd2, f)\n",
        "  print(\"test_haralick_fd were saved..\\n\")\n",
        "\n",
        "  with open(os.path.join(save_path, 'features_test', 'test_glcm_fd' + '.pkl'), 'wb') as f:\n",
        "          pickle.dump(glcm_fd2, f)\n",
        "  print(\"test_glcm_fd were saved..\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b7a8ee2-2880-4e3b-da62-4313ab3f503c",
        "id": "lMPQgrso2dlX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_variegation_fd were saved..\n",
            "\n",
            "test_color_feature_fd were saved..\n",
            "\n",
            "test_rgb_fd were saved..\n",
            "\n",
            "test_hsv_fd were saved..\n",
            "\n",
            "test_lab_fd were saved..\n",
            "\n",
            "test_lbp_fd were saved..\n",
            "\n",
            "test_haralick_fd were saved..\n",
            "\n",
            "test_glcm_fd were saved..\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "Y4tqME764D_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge 1"
      ],
      "metadata": {
        "id": "aEcv1C8Q4GSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "1dl6BIirFand"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df1 = pd.read_csv('/content/drive/MyDrive/CAD_Dataset/Challenge1/test.csv')"
      ],
      "metadata": {
        "id": "fNOirfBPFSuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Open test features \n",
        "save_path = '/content/drive/MyDrive/CAD_Dataset/Challenge1/'\n",
        "\n",
        "# ---  Read Saved test Features :  ---------------------------------\n",
        "with open(os.path.join(save_path, 'features_test', 'test_variegation_fd' + '.pkl'), 'rb') as file:\n",
        "    test_variegation_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_color_feature_fd' + '.pkl'), 'rb') as file:\n",
        "    test_color_feature_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_rgb_fd' + '.pkl'), 'rb') as file:\n",
        "    test_rgb_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_hsv_fd' + '.pkl'), 'rb') as file:\n",
        "    test_hsv_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_lab_fd' + '.pkl'), 'rb') as file:\n",
        "    test_lab_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_lbp_fd' + '.pkl'), 'rb') as file:\n",
        "    test_lbp_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_haralick_fd' + '.pkl'), 'rb') as file:\n",
        "    test_haralick_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_glcm_fd' + '.pkl'), 'rb') as file:\n",
        "    test_glcm_fd = pickle.load(file)  "
      ],
      "metadata": {
        "id": "mBtE43iZ4Lmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_variegation_fd.shape)\n",
        "print(test_color_feature_fd.shape)\n",
        "print(test_rgb_fd.shape)\n",
        "print(test_hsv_fd.shape)\n",
        "print(test_lab_fd.shape)\n",
        "print(test_lbp_fd.shape)\n",
        "print(test_haralick_fd.shape)\n",
        "print(test_glcm_fd.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qorut_bFEEn",
        "outputId": "e0ca86c5-c05c-4334-f16f-0d416c8c7403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6340, 3)\n",
            "(6340, 12)\n",
            "(6340, 192)\n",
            "(6340, 192)\n",
            "(6340, 192)\n",
            "(6340, 18)\n",
            "(6340, 13)\n",
            "(6340, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "RWOSEzi7Fdp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/CAD_Dataset/Challenge1/'\n",
        "\n",
        "with open(os.path.join(save_path, 'models', 'xgboost_final' + '.pkl'), 'rb') as file:\n",
        "    xgboost = pickle.load(file)\n",
        "with open(os.path.join(save_path, 'models', 'svm_final' + '.pkl'), 'rb') as file: \n",
        "    svm = pickle.load(file)"
      ],
      "metadata": {
        "id": "x8PvHhVlFe9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "vPtFH-90GAM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features \n",
        "test_features = np.hstack([test_variegation_fd, \n",
        "                            test_color_feature_fd[:, 3:], \n",
        "                            test_rgb_fd[:, 64:], \n",
        "                            test_hsv_fd, \n",
        "                            test_lab_fd, \n",
        "                            test_lbp_fd, \n",
        "                            test_haralick_fd[:, [0, 1, 2, 3, 4, 6, 9, 10]]])"
      ],
      "metadata": {
        "id": "gdYjHltDGGJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm_probs = svm.predict_proba(test_features)\n",
        "xgbt_probs = xgboost.predict_proba(test_features)\n",
        "y_probs = (svm_probs + xgbt_probs)/2\n",
        "y_preds = np.argmax(y_probs, axis=1)"
      ],
      "metadata": {
        "id": "OFExxj4NGBuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(y_preds[y_preds==0]))\n",
        "print(len(y_preds[y_preds==1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNvS9M8oIE4g",
        "outputId": "3e5364df-f85c-47cb-8244-ace7b53192f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3266\n",
            "3074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df1['labels'] = y_preds\n",
        "test_df1.to_csv(f'{save_path}/test_results.csv')"
      ],
      "metadata": {
        "id": "a-bCa7zvIbtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenge 2 "
      ],
      "metadata": {
        "id": "Up5ClwOS4I5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data"
      ],
      "metadata": {
        "id": "eExRwkJl2lVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df2 = pd.read_csv('/content/drive/MyDrive/CAD_Dataset/Challenge2/test.csv')\n",
        "\n",
        "# Open test features \n",
        "save_path = '/content/drive/MyDrive/CAD_Dataset/Challenge2/'\n",
        "\n",
        "# ---  Read Saved test Features :  ---------------------------------\n",
        "with open(os.path.join(save_path, 'features_test', 'test_variegation_fd' + '.pkl'), 'rb') as file:\n",
        "    test_variegation_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_color_feature_fd' + '.pkl'), 'rb') as file:\n",
        "    test_color_feature_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_rgb_fd' + '.pkl'), 'rb') as file:\n",
        "    test_rgb_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_hsv_fd' + '.pkl'), 'rb') as file:\n",
        "    test_hsv_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_lab_fd' + '.pkl'), 'rb') as file:\n",
        "    test_lab_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_lbp_fd' + '.pkl'), 'rb') as file:\n",
        "    test_lbp_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_haralick_fd' + '.pkl'), 'rb') as file:\n",
        "    test_haralick_fd = pickle.load(file)\n",
        "\n",
        "with open(os.path.join(save_path, 'features_test', 'test_glcm_fd' + '.pkl'), 'rb') as file:\n",
        "    test_glcm_fd = pickle.load(file)  "
      ],
      "metadata": {
        "id": "r04IeOFP4MBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_variegation_fd.shape)\n",
        "print(test_color_feature_fd.shape)\n",
        "print(test_rgb_fd.shape)\n",
        "print(test_hsv_fd.shape)\n",
        "print(test_lab_fd.shape)\n",
        "print(test_lbp_fd.shape)\n",
        "print(test_haralick_fd.shape)\n",
        "print(test_glcm_fd.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JytCySmz2bl0",
        "outputId": "f9119dac-ccf7-497d-bb8c-9518ea75c580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(226, 3)\n",
            "(226, 12)\n",
            "(226, 192)\n",
            "(226, 192)\n",
            "(226, 192)\n",
            "(226, 18)\n",
            "(226, 13)\n",
            "(226, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models"
      ],
      "metadata": {
        "id": "Eud9gps52p1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/CAD_Dataset/Challenge2/'\n",
        "\n",
        "with open(os.path.join(save_path, 'models', 'voting_smund1700_yeo_newAll_clf6' + '.pkl'), 'rb') as file:\n",
        "    eclf = pickle.load(file)"
      ],
      "metadata": {
        "id": "YkKLKQTx2tkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prediction"
      ],
      "metadata": {
        "id": "ReAwGai2XCUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features :\n",
        "test_features_all = np.hstack([test_variegation_fd, \n",
        "                               test_color_feature_fd, \n",
        "                               test_rgb_fd, \n",
        "                               test_hsv_fd, \n",
        "                               test_lab_fd, \n",
        "                               test_lbp_fd, \n",
        "                               test_haralick_fd, \n",
        "                               test_glcm_fd]) "
      ],
      "metadata": {
        "id": "_1ysnxzZW2q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = eclf.predict(test_features_all)  # Predictions\n",
        "print('Label 0:', np.count_nonzero(y_pred==0))\n",
        "print('Label 1:', np.count_nonzero(y_pred==1))\n",
        "print('Label 2:', np.count_nonzero(y_pred==2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FejAjRbUjl2K",
        "outputId": "ebe1086d-523e-43ba-f54e-cb30c0f78159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0: 1079\n",
            "Label 1: 907\n",
            "Label 2: 135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df2['labels'] = y_pred\n",
        "test_df2.to_csv(f'{save_path}/test_results_challenge2.csv')"
      ],
      "metadata": {
        "id": "If_3yMZ5XktD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}